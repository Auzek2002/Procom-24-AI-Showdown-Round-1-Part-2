{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyYaCOg2+NBZq5jdWXaF+T"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing LIbs:**"
      ],
      "metadata": {
        "id": "gGTCOo6RDr8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJV_-99SDcG5",
        "outputId": "3db35b33-aac9-47df-e6a2-7a77650a47d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c60e90ce3514>:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
            "  from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras import datasets,layers,Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,GlobalAveragePooling2D\n",
        "from zipfile import ZipFile\n",
        "import os,glob\n",
        "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
        "from keras.models import Model\n",
        "from sklearn import preprocessing\n",
        "from keras.layers import BatchNormalization\n",
        "from zipfile import ZipFile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the DataSet:**"
      ],
      "metadata": {
        "id": "YGj3zl5CD1Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "T7s1DLu7Dxfj",
        "outputId": "036c9fc7-a968-437d-8b0d-8cec8a942b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ce58ffbe-8c7b-46f0-aa54-d8276fb51655\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ce58ffbe-8c7b-46f0-aa54-d8276fb51655\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 76 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c ai-mlprocom24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LhFC-bID-Xq",
        "outputId": "998e2d9c-aa62-4408-a221-667705d28c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ai-mlprocom24.zip to /content\n",
            " 99% 376M/380M [00:03<00:00, 48.5MB/s]\n",
            "100% 380M/380M [00:03<00:00, 103MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/content/ai-mlprocom24.zip\"\n",
        "with ZipFile(file,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbCO8p9dEEzB",
        "outputId": "232d459a-c897-4f45-9b74-024aef8cf4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Train.csv')\n",
        "\n",
        "# Load and preprocess images\n",
        "image_data = []\n",
        "labels = []\n",
        "class_names= ['Normal','Abnormal']\n",
        "for index, row in df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])   #row['ID']=img001.jpg -> /content/train_images/img001.jpg\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize the image to a fixed size\n",
        "    image = img_to_array(image)\n",
        "    image_data.append(image)\n",
        "    labels.append(row['Label'])\n",
        "\n"
      ],
      "metadata": {
        "id": "qa_MILdcES9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Label Encoding:**"
      ],
      "metadata": {
        "id": "6flRRyUgN-da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_new = []\n",
        "for i in labels:\n",
        "    labels_new.append(class_names.index(i))\n",
        "labels = labels_new\n",
        "labels = tf.keras.utils.to_categorical(labels)"
      ],
      "metadata": {
        "id": "2IekK4LyOCco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = np.array(image_data, dtype='float32') / 255.0    #Normalization"
      ],
      "metadata": {
        "id": "sxayYPH4P1iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16 , preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img , img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.densenet import DenseNet121"
      ],
      "metadata": {
        "id": "gLjNXq2CJAnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using VGG16:**"
      ],
      "metadata": {
        "id": "_KgcftqDNlVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r , c = 224 ,224\n",
        "vgg = VGG16(weights='imagenet',include_top=False,input_shape=(r,c,3))   # 224 x 224 x 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-B95NsMNLfK",
        "outputId": "6c3f84d0-a519-485a-edaa-4d188b181d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "G40RnLC7Ok58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg_model(bottom_model,classes):\n",
        "  top_model=bottom_model.output\n",
        "  top_model = GlobalAveragePooling2D()(top_model)\n",
        "  top_model = Dense(1024,activation='relu')(top_model)\n",
        "  top_model = Dense(512,activation='relu')(top_model)\n",
        "  top_model = Dense(64,activation='relu')(top_model)\n",
        "  top_model = Dense(32,activation='relu')(top_model)\n",
        "  top_model = Dense(2,activation='softmax')(top_model)  #could have also used activation = 'sigmoid'\n",
        "  return top_model"
      ],
      "metadata": {
        "id": "B0Dkv1zjOnjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_head = vgg_model(vgg,2)\n",
        "model = Model(inputs=vgg.input,outputs=model_head)"
      ],
      "metadata": {
        "id": "rq_FiYlgOutc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(image_data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zASa129BPT7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diAKJL_6Ox4x",
        "outputId": "5a3db768-3002-483e-979d-abf7822c29c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15799778 (60.27 MB)\n",
            "Trainable params: 1085090 (4.14 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "7jv3CRRmO0CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=10,validation_data=(X_val, y_val),initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiK49NFNO9aZ",
        "outputId": "c56a3fa0-cc3c-454c-a8f6-919d017919a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 52s 15s/step - loss: 0.7882 - accuracy: 0.4769 - val_loss: 0.7045 - val_accuracy: 0.4706\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 56s 15s/step - loss: 0.6942 - accuracy: 0.4769 - val_loss: 0.6991 - val_accuracy: 0.4706\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 48s 14s/step - loss: 0.6969 - accuracy: 0.4769 - val_loss: 0.6887 - val_accuracy: 0.4706\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 50s 15s/step - loss: 0.6792 - accuracy: 0.4769 - val_loss: 0.6577 - val_accuracy: 0.8235\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 57s 20s/step - loss: 0.6568 - accuracy: 0.7077 - val_loss: 0.6488 - val_accuracy: 0.5882\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 49s 15s/step - loss: 0.6436 - accuracy: 0.6000 - val_loss: 0.6415 - val_accuracy: 0.5882\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 47s 14s/step - loss: 0.6393 - accuracy: 0.5538 - val_loss: 0.6353 - val_accuracy: 0.5882\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 48s 15s/step - loss: 0.6288 - accuracy: 0.6615 - val_loss: 0.6172 - val_accuracy: 0.7647\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 47s 14s/step - loss: 0.6235 - accuracy: 0.7538 - val_loss: 0.6231 - val_accuracy: 0.6471\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 52s 17s/step - loss: 0.6237 - accuracy: 0.6615 - val_loss: 0.6036 - val_accuracy: 0.7647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e868010cfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Resnet:**"
      ],
      "metadata": {
        "id": "40ED6Vw7QxGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess images\n",
        "image_data_r = []\n",
        "labels_r = []\n",
        "class_names= ['Normal','Abnormal']\n",
        "for index, row in df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize the image to a fixed size\n",
        "    image = img_to_array(image)\n",
        "    image_data_r.append(image)\n",
        "    labels_r.append(row['Label'])"
      ],
      "metadata": {
        "id": "5m7ukSspQzqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data_r = np.array(image_data_r, dtype='float32') / 255.0\n",
        "labels_r = np.array(labels_r)\n",
        "\n",
        "# Convert labels to binary format (0 for 'normal' and 1 for 'abnormal')\n",
        "labels_r = np.where(labels_r == 'normal', 0, 1)"
      ],
      "metadata": {
        "id": "pTAzHPtWRFk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_resnet = Model(inputs=resnet.input,outputs=predictions)\n",
        "model_resnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwfAakkCRTzQ",
        "outputId": "9c22613c-6ea0-4ec6-b623-7e9b4d87d5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 112, 112, 64)         0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 56, 56, 256)          0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 56, 56, 256)          0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 56, 56, 256)          0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 56, 56, 256)          0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 28, 28, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 28, 28, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 28, 28, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 28, 28, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 28, 28, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1024)                 2098176   ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1)                    1025      ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25686913 (97.99 MB)\n",
            "Trainable params: 25633793 (97.79 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "xv-zfre7S-vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "q_1tvXZbTDEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(image_data, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "trpKmlfRTDHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load and preprocess images\n",
        "image_data_r = []\n",
        "labels_r = []\n",
        "class_names = ['Normal', 'Abnormal']\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize the image to a fixed size\n",
        "    image = img_to_array(image)\n",
        "    image_data_r.append(image)\n",
        "    labels_r.append(row['Label'])\n",
        "\n",
        "image_data_r = np.array(image_data_r, dtype='float32') / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to binary format (0 for 'Normal' and 1 for 'Abnormal')\n",
        "labels_r = np.array(labels_r)\n",
        "labels_r = np.where(labels_r == 'Normal', 0, 1)\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers for classification\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the final model\n",
        "model_resnet = Model(inputs=resnet.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model_resnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(image_data_r, labels_r, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model_resnet.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "mdxq-l76gJp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using InceptionV3**"
      ],
      "metadata": {
        "id": "cYR1OR4BTW8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_data_i = []\n",
        "labels_i = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (299, 299))\n",
        "    image = img_to_array(image)\n",
        "    image_data_i.append(image)\n",
        "    labels_i.append(row['Label'])\n",
        "\n",
        "\n",
        "image_data_i = np.array(image_data_i, dtype='float32') / 255.0\n",
        "labels_i = np.array(labels_i)\n",
        "\n",
        "# Convert labels to binary format (0 for 'normal' and 1 for 'abnormal')\n",
        "labels_i = np.where(labels_i == 'normal', 0, 1)\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(image_data_i, labels_i, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "base_model_i = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "x = base_model_i.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions_i = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_i = Model(inputs=base_model_i.input, outputs=predictions_i)\n",
        "\n",
        "for layer in base_model_i.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_i.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_i.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8aIVJjbYUjZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using DenseNet:**"
      ],
      "metadata": {
        "id": "l7F1-r7xYWaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_data_d = []\n",
        "labels_d = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize the image to match DenseNet input size\n",
        "    image = img_to_array(image)\n",
        "    image_data_d.append(image)\n",
        "    labels_d.append(row['Label'])\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "image_data_d = np.array(image_data_d, dtype='float32') / 255.0  # Normalize pixel values\n",
        "labels_d = np.array(labels_d)\n",
        "\n",
        "# Convert labels to binary format (0 for 'normal' and 1 for 'abnormal')\n",
        "labels_d = np.where(labels_d == 'normal', 0, 1)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(image_data_d, labels_d, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the pre-trained DenseNet121 model\n",
        "base_model_d = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Modify the model for transfer learning\n",
        "x = base_model_d.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions_d = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the final model\n",
        "model_d = Model(inputs=base_model_d.input, outputs=predictions_d)\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model_d.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model_d.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_d.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, accuracy = model.evaluate(X_val, y_val)\n",
        "# print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions\n",
        "# Assuming you have a test set or new images to predict on, you can load and preprocess them similarly to the training data\n",
        "# Then use the trained model to make predictions\n",
        "# predictions = model.predict(test_images)\n"
      ],
      "metadata": {
        "id": "dKpJJeS3YVY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making predictions:**"
      ],
      "metadata": {
        "id": "bqUFFKWeaVSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_df = pd.read_csv('/content/Test.csv')\n",
        "\n",
        "# Load and preprocess images from the Test folder\n",
        "test_images = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])  # Assuming the images are in a folder named 'Test'\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (229, 229))  # Resize the image to match InceptionV3 input size\n",
        "    image = img_to_array(image) / 255.0  # Normalize pixel values\n",
        "    test_images.append(image)\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "predictions = model_i.predict(test_images)\n",
        "\n",
        "# Convert predictions to original label format ('normal' or 'abnormal')\n",
        "predicted_labels = np.where(predictions > 0.5, 'abnormal', 'normal')\n",
        "\n",
        "# Add the predicted labels to the DataFrame\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.head()\n",
        "# Save the DataFrame with the predicted labels to a new CSV file\n",
        "test_df.to_csv('Test_Predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "AWjyZaGZabDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('Test_Predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "5DDbnaDxb-85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess images from the Test folder\n",
        "test_images = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])  # Assuming the images are in a folder named 'Test'\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (299, 299))  # Resize the image to match InceptionV3 input size\n",
        "    image = img_to_array(image) / 255.0  # Normalize pixel values\n",
        "    test_images.append(image)\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "predictions = model_i.predict(test_images)\n",
        "\n",
        "# Convert predictions to original label format ('normal' or 'abnormal')\n",
        "predicted_labels = np.where(predictions > 0.5, 'abnormal', 'normal')\n",
        "\n",
        "# Add the predicted labels to the DataFrame\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.head()\n",
        "\n",
        "# Save the DataFrame with the predicted labels to a new CSV file\n",
        "#test_df.to_csv('Test_Predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "HFJhoCOBccdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('Test_Predictions_Inception.csv', index=False)"
      ],
      "metadata": {
        "id": "yVgS4sXWdu-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess images from the Test folder\n",
        "test_images = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])  # Assuming the images are in a folder named 'Test'\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize the image to match InceptionV3 input size\n",
        "    image = img_to_array(image) / 255.0  # Normalize pixel values\n",
        "    test_images.append(image)\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Convert predictions to original label format ('normal' or 'abnormal')\n",
        "predicted_labels = np.where(predictions > 0.5, 'abnormal', 'normal')\n",
        "\n",
        "# Add the predicted labels to the DataFrame\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.head()\n",
        "\n",
        "# Save the DataFrame with the predicted labels to a new CSV file\n",
        "test_df.to_csv('Test_Predictions_vgg.csv', index=False)"
      ],
      "metadata": {
        "id": "hPbRphxid3GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting features using Densenet and then using SVC to classify if the cell is normal or abnormal**"
      ],
      "metadata": {
        "id": "gjG8IkZJh2Y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using SVC**"
      ],
      "metadata": {
        "id": "iK4qnymOkYL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained ResNet50 model\n",
        "features_resnet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    features = resnet.predict(image)\n",
        "    features_resnet.append(features.flatten())\n",
        "    labels.append(row['Label'])\n",
        "\n",
        "features_resnet = np.array(features_resnet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_resnet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a machine learning model (e.g., SVM) using the extracted features\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    features = resnet.predict(image)\n",
        "    features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(features_test)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predictions\n",
        "test_df.to_csv('Test_Predictions_1.0.csv', index=False)\n"
      ],
      "metadata": {
        "id": "AqjXfJJAgu4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using XGBoost**"
      ],
      "metadata": {
        "id": "qTfvt8kalUqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
        "\n",
        "features_resnet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_resnet.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_resnet = np.array(features_resnet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_resnet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an XGBoost model using the extracted features\n",
        "model_xgb = XGBClassifier()\n",
        "model_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_xgb.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_xgb.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_XGBoost.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "Hb0Qhi0SjhFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVC + Mobilenet:**"
      ],
      "metadata": {
        "id": "tL_eHjGmpJQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained MobileNetV2 model\n",
        "mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=mobilenet.input, outputs=mobilenet.output)\n",
        "\n",
        "features_mobilenet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match MobileNetV2 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_mobilenet.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_mobilenet = np.array(features_mobilenet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_mobilenet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM model using the extracted features\n",
        "model_svc = SVC()\n",
        "model_svc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_svc.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match MobileNetV2 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_svc.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_SVC_Mobilenet.csv', index=False)\n"
      ],
      "metadata": {
        "id": "F4XHcoQkpHbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVC + InceptionV3**"
      ],
      "metadata": {
        "id": "cdBWB6TpqAuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained InceptionV3 model\n",
        "inceptionv3 = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "model = Model(inputs=inceptionv3.input, outputs=inceptionv3.output)\n",
        "\n",
        "features_inceptionv3 = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (299, 299))  # Resize the image to match InceptionV3 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_inceptionv3.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_inceptionv3 = np.array(features_inceptionv3)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_inceptionv3, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM model using the extracted features\n",
        "model_svc = SVC()\n",
        "model_svc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_svc.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (299, 299))  # Resize the image to match InceptionV3 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_svc.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_SVC_Inception.csv', index=False)\n"
      ],
      "metadata": {
        "id": "nDATq0knpZG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest + Resnet**"
      ],
      "metadata": {
        "id": "RixvoIv-qgwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
        "\n",
        "features_resnet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_resnet.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_resnet = np.array(features_resnet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_resnet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest model using the extracted features\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_rf.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_rf.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_Random.csv', index=False)\n"
      ],
      "metadata": {
        "id": "NfFoXO4OqUUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Trees + resnet50**"
      ],
      "metadata": {
        "id": "J3amL639rDEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
        "\n",
        "features_resnet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_resnet.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_resnet = np.array(features_resnet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_resnet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree model using the extracted features\n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_dt.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_dt.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_Decision_Trees_resnet.csv', index=False)\n"
      ],
      "metadata": {
        "id": "VUCF-Z7yq5VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adaboost + Resnet50**"
      ],
      "metadata": {
        "id": "j5HvHSJ9sxiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
        "\n",
        "features_resnet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_resnet.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_resnet = np.array(features_resnet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_resnet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an AdaBoost model using the extracted features and DecisionTreeClassifier as base estimator\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "model_ab = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50)\n",
        "model_ab.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_ab.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_ab.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_Adaboost_resnet.csv', index=False)\n"
      ],
      "metadata": {
        "id": "xrmZhiLrr2og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adaboost + Xception**"
      ],
      "metadata": {
        "id": "K5OuKCGTtRiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained Xception model\n",
        "xception = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "model = Model(inputs=xception.input, outputs=xception.output)\n",
        "\n",
        "features_xception = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (299, 299))  # Resize the image to match Xception input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_xception.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_xception = np.array(features_xception)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_xception, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an AdaBoost model using the extracted features and DecisionTreeClassifier as base estimator\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "model_ab = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50)\n",
        "model_ab.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_ab.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (299, 299))  # Resize the image to match Xception input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_ab.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_Adaboost_Xception.csv', index=False)\n"
      ],
      "metadata": {
        "id": "RiaveO1As_U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVC + Xception**"
      ],
      "metadata": {
        "id": "tYF5iDI6tw1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained Xception model\n",
        "xception = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "model = Model(inputs=xception.input, outputs=xception.output)\n",
        "\n",
        "features_xception = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (299, 299))  # Resize the image to match Xception input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_xception.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_xception = np.array(features_xception)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_xception, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVC model using the extracted features\n",
        "model_svc = SVC()\n",
        "model_svc.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_svc.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (299, 299))  # Resize the image to match Xception input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_svc.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_SVC_Xception.csv', index=False)\n"
      ],
      "metadata": {
        "id": "HQy2jNQBtgZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN + Resnet**"
      ],
      "metadata": {
        "id": "k53kJVG4ual1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
        "\n",
        "features_resnet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_resnet.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_resnet = np.array(features_resnet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_resnet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a KNN model using the extracted features\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "model_knn.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_knn.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_knn.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_KNN_resnet.csv', index=False)\n"
      ],
      "metadata": {
        "id": "pLp9_73iuK9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes + Resnet50**"
      ],
      "metadata": {
        "id": "VT8KH6MnvNDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the CSV file containing image names and labels for training\n",
        "train_df = pd.read_csv('Train.csv')\n",
        "\n",
        "# Load the images and extract features using a pre-trained ResNet50 model\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
        "\n",
        "features_resnet = []\n",
        "labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = os.path.join('/content/train_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_resnet.append(features.flatten())\n",
        "        labels.append(row['Label'])\n",
        "\n",
        "features_resnet = np.array(features_resnet)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numeric format\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_resnet, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Naive Bayes model using the extracted features\n",
        "model_nb = GaussianNB()\n",
        "model_nb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model_nb.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Use the trained model to make predictions on the test images\n",
        "test_df = pd.read_csv('Test.csv')\n",
        "features_test = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = os.path.join('/content/test_images', row['ID'])\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is not None:\n",
        "        image = cv2.resize(image, (224, 224))  # Resize the image to match ResNet50 input size\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "        features = model.predict(image)\n",
        "        features_test.append(features.flatten())\n",
        "\n",
        "features_test = np.array(features_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_nb.predict(features_test)\n",
        "\n",
        "# Convert numeric predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_df['Label'] = predicted_labels\n",
        "test_df.to_csv('Test_Predictions_Naive_Bayes_resnet50.csv', index=False)\n"
      ],
      "metadata": {
        "id": "tgbpsxOVu3dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YM_ULvtuvadh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}